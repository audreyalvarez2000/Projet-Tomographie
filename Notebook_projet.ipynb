{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0e55cc",
   "metadata": {},
   "source": [
    "# Notebook pédagogique pour le TP Tomographie\n",
    "\n",
    "## Introduction\n",
    "\n",
    "La tomographie est une technique d’imagerie permettant la reconstruction\n",
    "d'images en coupe d’un objet. La tomographie à rayon X repose sur l'interaction des dits rayons avec la matière.\n",
    "\n",
    "Dans notre cas, c’est l’objet qui tourne et non la source. \n",
    "La reconstruction sert à reproduire un objet 3D en un ensemble de coupes 2D. L’intérêt de cette méthode est de pouvoir détecter une anomalie à l’intérieur de l’objet sans avoir à l'ouvrir ainsi que de connaître sa structure.\n",
    "\n",
    "Deux méthodes de reconstruction sont possibles, une méthode dite analytique et une méthode itérative.\n",
    "\n",
    "Dans ce notebook vous allez, étape par étape, découvrir le traitement d'images et les différents algorithmes en question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84344f",
   "metadata": {},
   "source": [
    "## Étape préliminaire : Lancer Anaconda et activer l'environnement\n",
    "\n",
    "Tout d'abord il faut lancer Anaconda. Ensuite quand celui-ci est ouvert, ouvrez le terminal Anaconda prompt si celui-ci ne c'est pas ouvert. Tapez-y la commande *'conda activate tomo2122'* pour activer l'environnement. \n",
    "\n",
    "Ensuite en haut à gauche dans *'Applications on'* sélectionnez *'tomo2122'.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b8d16",
   "metadata": {},
   "source": [
    "## Étape 0 : Importer les bibliothèques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f392463-5f3d-4dee-906c-dd76afe46e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomopy\n",
    "import dxchange\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from imagestacks import create_animation\n",
    "from IPython.core.display import HTML\n",
    "from PIL import Image, ImageFilter\n",
    "%matplotlib inline\n",
    "import skimage\n",
    "from skimage.transform import iradon\n",
    "from skimage.transform import radon\n",
    "from skimage.exposure import rescale_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4c596-1dac-4830-9fa6-1504b1294f47",
   "metadata": {},
   "source": [
    "## Étape 1 : Traitement des images pour améliorer la qualité\n",
    "\n",
    "\n",
    "Afin d'avoir une meilleure reconstruction il faut préalablement améliorer la qualité de nos images pour enlever le bruit.\n",
    "\n",
    "1. Le premier filtre que vous allez tester est le filtre flou (blur).\n",
    "\n",
    "Vous allez ouvrir une image de votre choix de votre dossier (contenant les images issues de la machine X) et appliquer le filtre puis afficher votre image. Remplacez les \\ par des doubles \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0d100-c129-41fa-a0c5-eb3c1ebc15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ouverture de l'image à traiter\n",
    "image = cv2.imread('mettre le chemin de l image à traiter') # lire l'image \n",
    "image2 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY ) # convertir BGR en RGB permet d'avoir sur 1 pixel une seule couleur et pas 3 \n",
    "plt.imshow(image2,cmap='gray') #converti en GRAY \n",
    "\n",
    "#Filtre\n",
    "figure_size = 9 # les dimension de l'axe x and y du noyau.\n",
    "new_image = cv2.blur(image2,(figure_size, figure_size)) #Filtre blur (flou)\n",
    "plt.figure(figsize=(11,6))\n",
    "\n",
    "#Affiche l'image d'origine et l'image après filtrage\n",
    "plt.subplot(121),plt.imshow(image2,cmap='gray'),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(122), plt.imshow(new_image, cmap='gray'),plt.title('filtre_blur')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74fcc1f-81e5-4f64-9b93-22cd4ba627ee",
   "metadata": {},
   "source": [
    "Ce filtre permet donc d’obtenir une image floue de l’originale. Ce filtre n’est pas le résultat attendu car nous aimerions obtenir uniquement le fond uniforme et ne pas toucher à l’image de l'objet observé.\n",
    "\n",
    "2. Le deuxième filtre que vous allez tester est le flou gaussien (GaussianBlur).\n",
    "\n",
    "Pour pouvoir exécuter le code ci-dessous vous devez créer un dossier vide sur l'ordinateur dans lequel les images traitées seront enregistrées. Ensuite vous devrez remplacer \"Chemin du dossier créé pour y mettre les images traitées+nom de l'image%i.tif\" par le chemin de votre dossier et le nom que vous souhaitez donner à vos images.\n",
    "\n",
    "Voici un exemple : \"/Users/audreyaudrey/Desktop/Projet multi/Dossier image traitée/imtrait%i.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70ed2c-02f0-4f88-97de-c16f41414324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation\n",
    "i=0\n",
    "dossier = 'Mettre le chemin de la première image du dossier'\n",
    "num_image = [] #on definit des listes qui serviront à tracer les courbes\n",
    "\n",
    "#Bloucle pour traiter tout les images avec le filtre\n",
    "for image in glob.glob(dossier+\"/*.tif\"):\n",
    "    print('-----------------')\n",
    "    print('image n°: ',i)\n",
    "    num_image.append(i)#ajouter à la liste num_image\n",
    "    img = cv2.imread(image)# lire l'image\n",
    "    gaussian= cv2.GaussianBlur(img,(5,5),5) #Filtre GaussianBlur (flou gaussien suit une loi gaussienne)\n",
    "    \n",
    "    #Permet d'enregistrer les images filtrées\n",
    "    cv2.imwrite(\"Chemin du dossier créé pour y mettre les images traitées/+nom de l'image%i.tif\"%i,gaussian)\n",
    "    \n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74170830-7d4f-4ff9-9c09-16261de69a33",
   "metadata": {},
   "source": [
    "Ce filtre permet  de définir un flou à partir d’un noyau défini dans la fonction gaussienne. \n",
    "Ce filtre permet donc d’avoir un bruit de fond plus lisse sans endommager l’image de l’objet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3533639-0551-4674-bb55-dc0854a746e6",
   "metadata": {},
   "source": [
    "## Étape 2 : Choix du fichier et ouverture de celui-ci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49581316",
   "metadata": {},
   "source": [
    "### 1. Choix du fichier\n",
    "\n",
    "Pour pouvoir traiter les images issues de la machine à rayon X il faut choisir le fichier. Il faut sélectionner le chemin de la première image du dossier les contenant. Ce dossier est celui que vous venez de créer avec vos images traitées dedans.\n",
    "Attention, si le numéro de votre image est 1 (ou 0001 par exemple), il faut mettre dans indice i+1, et i si la première image est numérotée 0.\n",
    "Dans fname, remplacer Mettre le chemin par celui de votre image entre apostrophes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393e4923-af0b-40b2-88dd-30dfb85d2505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180]\n",
      "chemin de la premiere image de votre dossier créé à étape 1\n"
     ]
    }
   ],
   "source": [
    "fname = 'chemin de la premiere image de votre dossier créé à étape 1'\n",
    "ind = [i+1 for i in range(180)]\n",
    "print(ind)\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61fb8d",
   "metadata": {},
   "source": [
    "### 2. Lecture du dossier\n",
    "Comme c'est un dossier d'images au format tif que l'on souhaite lire, on doit utiliser la bibliothèque dxchange et la fonction reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed9e091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:04.059799\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "proj = dxchange.reader.read_tiff_stack(fname, ind)\n",
    "end = datetime.datetime.now() \n",
    "duree = end - start #Pour mesurer le temps mis pour effectuer la ligne proj\n",
    "print(duree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be573549",
   "metadata": {},
   "source": [
    "## Étape 3: Traitement de la taille des images et affichage\n",
    "\n",
    "Pour cette étape, les images vont être réduite pour diminuer le temps d'exécution grâce à la fonction misc.morph.downsample de la bibliothèque tomopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3cf95-2947-4a35-86e4-823bf943d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diminuer la taille des images\n",
    "print('avant',proj.shape)\n",
    "down = tomopy.misc.morph.downsample(proj, level=1, axis=1)#axe 1 lignes: faire la moyenne des pixels 2 à 2\n",
    "down = tomopy.misc.morph.downsample(down, level=1, axis=2)# axe 2 colonnes: faire la moyenne des pixels 2 à 2\n",
    "#Avec axe 0 on aurait pris l'image complète qu'on aurait moyener avec tous les tilts ce qui aurait eu un rendu flou\n",
    "print('apres',down.shape)\n",
    "\n",
    "\n",
    "#afficher la  1ere image avant downsampling\n",
    "image0 = proj[0, :, :]#image zéro, on prend tous les pixels horizontaux et verticaux: toute la matrice des pixels\n",
    "plt.imshow(image0, cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#afficher la  1ere image apres downsampling\n",
    "image0 = down[0, :, :]\n",
    "plt.imshow(image0, cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "#Pour faire afficher les images les unes après l'autre\n",
    "yxratio=down.shape[2]/down.shape[1]\n",
    "anim2 = create_animation(down, 4,4/yxratio)\n",
    "display(HTML(anim2.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4dec8a",
   "metadata": {},
   "source": [
    "## Étape 4 : Centre de rotation et vérification\n",
    "\n",
    "1. Trouver le centre de rotation\n",
    "\n",
    "Pour pouvoir appliquer un algorithme de reconstruction, il faut également regarder le centre de rotation des images afin de vérifier que ce centre n’est pas décalé en fonction de l’angle de projection. \n",
    "Dans la bibliothèque Tomopy il y a la fonction find_center qui permet de trouver ce centre de rotation d’une image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e5516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomopy\n",
    "ang = tomopy.angles(180) # Genere des angles de 0° à 180°\n",
    "rot_center = tomopy.find_center(down, ang, init=None, ind=0, tol=0.5)\n",
    "print(rot_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ca8b3",
   "metadata": {},
   "source": [
    "Le paramètre ind permet d’indiquer vers quelle valeur de x se trouve le centre à vue d'œil. Cela permet d’aider la fonction à trouver cette valeur.\n",
    "\n",
    "Afin de pouvoir effectuer la vérification sans modifier les images pour la reconstruction, vous allez créer un deuxième down nommé down2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86594ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "down2 = tomopy.misc.morph.downsample(proj, level=1, axis=1)#axe 1 lignes: faire la moyenne des pixels 2 à 2\n",
    "down2 = tomopy.misc.morph.downsample(down2, level=1, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aac29a",
   "metadata": {},
   "source": [
    "Maintenant vous allez vérifier que le centre de rotation trouvé précédemment est correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permet de vérifier le centre de rotation\n",
    "#Trace deux lignes: 1-vertical représentant le centre de rotation. \n",
    "#2-horizontal: repere pour vérifier si un détail tourne bien à la meme distance du centre de rotation lors des differents angles. \n",
    "\n",
    "for k in range(180):\n",
    "    \n",
    "    down2[k, :, :]= cv2.line(down2[k, :, :], (int(rot_center),0),(int(rot_center),700), (255,255,255),6) #tracé de la ligne pour verifier le centre de rotation\n",
    "    down2[k, :, :]= cv2.line(down2[k, :, :], (0,400),(500,400), (255,255,255),2) #verif perpendicularité axe rotation\n",
    "\n",
    "#permet d'afficher l'image avec la verification\n",
    "plt.imshow(image0, cmap='Greys_r') \n",
    "plt.show()\n",
    "\n",
    "#Animation pour vérifier la symétrie d'un détail par rapport à l'axe de rotation\n",
    "yxratio=down2.shape[2]/down2.shape[1]\n",
    "anim2 = create_animation(down2,4,4/yxratio)\n",
    "display(HTML(anim2.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335af42d",
   "metadata": {},
   "source": [
    "## Étape 5 : Normalisation des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57325334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normaliser avec loi log pour loi de beer lambert\n",
    "norm = tomopy.prep.normalize.minus_log(down, ncore=None, out=None)\n",
    "\n",
    "\n",
    "#afficher la  1ere image normalisee\n",
    "image0 = norm[0, :, :]\n",
    "plt.imshow(image0, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd978b5",
   "metadata": {},
   "source": [
    "## Étape 6 : Les algorithmes en eux-mêmes\n",
    "\n",
    "### L'algorithme gridrec avec tomopy\n",
    "\n",
    "Cet algorithme fait partie de la méthode analytique par transformée de Fourier, c'est la méthode analytique la plus simple et basique disponible dans la bibliothèque Tomopy. En effet, à partir du dossier contenant les images de chaque projection à chaque angle, une transformé de Fourier 2D est faite par cet algorithme dans une grille polaire, suivi d´une interpolation dans un plan cartésien et enfin, il faut faire une transformée de Fourier inverse 2D pour passer dans l’espace réel. \n",
    "\n",
    "Le problème étant qu’il faut interpoler entre le polaire et le cartésien dans l’espace de Fourier. Ce qui implique que toute erreur d’interpolation dans l’espace de Fourier entraîne une erreur dans tout l’espace réel après la transformation inverse. Les calculs pour faire cette interpolation sont longs et très lourds. \n",
    "\n",
    "En revanche, cette méthode implique que l’image est pixelisée afin d’appliquer le théorème de la tranche de Fourier. Celui-ci stipule que la transformée de Fourier d’une projection d’une fonction f(x,y) vue sous un angle est égale à la tranche de la transformée de Fourier de f(x,y) sous cet angle. Ainsi, cela permet d’éliminer en théorie le bruit de chaque composante. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = tomopy.recon(norm, ang, center=rot_center, algorithm='gridrec') \n",
    "# Reconstruction objet avec prise en compte du centre de rotation.\n",
    "\n",
    "#Afficher l'image 25\n",
    "plt.imshow(rec[256,:,:])\n",
    "plt.show()\n",
    "\n",
    "yxratio=rec.shape[2]/rec.shape[1]\n",
    "anim2 = create_animation(rec,4,4/yxratio)\n",
    "display(HTML(anim2.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e32e91",
   "metadata": {},
   "source": [
    "### L'algorithme filtered backprojection (fbp) avec tomopy\n",
    "\n",
    "L’algorithme de rétroprojection filtrée est la méthode la plus utilisée pour la tomographie 2D. Deux étapes sont nécessaires : un filtrage des images de projections sur chaque angle puis une rétroprojection afin d’obtenir la reconstruction de l’objet en un ensemble de coupe 2D. \n",
    "\n",
    "Le filtre appliqué dans cet algorithme est appelé filtre de rampe. Ce filtre met à zéro la composante continue et introduit des valeurs négatives. Il permet également d’amplifier les fréquences élevées ce qui permet de générer dans le signal des transitions rapides. Les valeurs négatives sont utiles pour effacer les artefacts laissés par les autres projections.\n",
    "\n",
    "Cependant, ce filtre amplifie les hautes fréquences. C’est pourquoi, il est nécessaire d’ajouter à ce filtre, un filtre dit “Hamming” qui permettra d’atténuer cette amplification.  \n",
    "\n",
    "Voici une image qui permet de comparer les différents filtres\n",
    "\n",
    "![imagecomparative](https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs13246-014-0291-8/MediaObjects/13246_2014_291_Fig1_HTML.gif)\n",
    "\n",
    "Source : Investigation of effect of reconstruction filters on cone-beam computed tomography image quality, Kavitha Srinivasan, Mohammad Mohammadi, Justin Shepherd \n",
    "\n",
    "Avec tomopy, la rétroprojection filtrée est effectuée de manière analytique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94032a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec2 = tomopy.recon(norm, ang, center=rot_center, algorithm='fbp',filter_name='hamming') \n",
    "\n",
    "\n",
    "#Afficher l'image 25\n",
    "plt.imshow(rec2[256,:,:])\n",
    "plt.show()\n",
    "\n",
    "yxratio=rec2.shape[2]/rec2.shape[1]\n",
    "anim2 = create_animation(rec2, 4,4/yxratio)\n",
    "display(HTML(anim2.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4be44",
   "metadata": {},
   "source": [
    "### Utilisation d'AstraToolBox \n",
    "\n",
    "#### Algorithme \"FBP\" analytique \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "options={'proj_type': 'linear', 'method': 'ART', 'num_iter':180}\n",
    "\n",
    "#Reconstruction avec Astra Toolbox à partir des options décrites au dessus\n",
    "recon=tomopy.recon(proj,ang,center=rot_center,algorithm=tomopy.astra, options=options, ncore=1)\n",
    "recon=tomopy.circ_mask(recon,axis=0, ratio=0.95) #Appliquer un masque circulaire à un tableau 3D.\n",
    "\n",
    "#Afficher l'image 25\n",
    "plt.imshow(recon[256,:,:])\n",
    "plt.show()\n",
    "\n",
    "yxratio=recon.shape[2]/recon.shape[1]\n",
    "anim2 = create_animation(recon, 4,4/yxratio)\n",
    "display(HTML(anim2.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebacae29",
   "metadata": {},
   "source": [
    "#### Utilisation de la méthode CUDA utilisant un GPU, algorithme itératif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_options ={'MinConstraint':0}\n",
    "\n",
    "#methode utilisant un GPU, Permet d'avoir une reconstruction moins longue\n",
    "options = {'proj_type':'cuda', 'method':'SIRT_CUDA', 'num_iter':200, 'extra_options': extra_options}\n",
    "\n",
    "#Reconstruction avec Astra Toolbox à partir des options décrites au dessus\n",
    "recon2 = tomopy.recon(proj, ang, center=rot_center, algorithm=tomopy.astra, ncore=16, options=options)\n",
    "recon2=tomopy.circ_mask(recon2,axis=0, ratio=0.95) #Appliquer un masque circulaire à un tableau 3D.\n",
    "\n",
    "#Afficher l'image 25\n",
    "plt.imshow(recon2[256,:,:])\n",
    "plt.show()\n",
    "\n",
    "yxratio=recon2.shape[2]/recon2.shape[1]\n",
    "anim2 = create_animation(recon2, 4,4/yxratio)\n",
    "display(HTML(anim2.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e83f638",
   "metadata": {},
   "source": [
    "### Autre algorithme utilisant la transformée de Radon\n",
    "\n",
    "La transformée de Radon permet de faire l'intégration de la fonction représentant l'objet, soit f(x,y), selon des droites de différentes orientations.\n",
    "\n",
    "![principe_radon_transform](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSC4AZcJUDKqGfdL0CRJaw-XHwNP3BArQBlBnqa_ID8D3RlBGDRKl_oxT-RXwXM60e6T_E&usqp=CAU)\n",
    "\n",
    "Source : APPLICATION OF RADON TRANSFORM IN CT IMAGE MATCHING, Yufang Cai, Kuan Shen, Jue Wang \n",
    "\n",
    "La transformée de Radon permet d'obtenir le sinogramme. Or, les images que vous possédez forment déjà un sinogramme.\n",
    "\n",
    "Afin de faire la reconstruction, vous allez l'effectuer trois fois en faisant la transformée inverse de Radon mais une première fois sans filtre, une deuxième fois avec le filtre de Hanning et enfin avec le filtre de Hamming.\n",
    "\n",
    "Pour pouvoir exécuter le code ci-dessous vous devez créer un dossier vide sur l'ordinateur dans lequel les images traitées seront enregistrées. Ensuite vous devrez remplacer \"Chemin du dossier créé pour y mettre les images traitées+nom de l'image%i.tif\" par le chemin de votre dossier et le nom que vous souhaitez donner à vos images.\n",
    "\n",
    "Voici un exemple : 'R:\\\\4eme Annee GP\\\\TP4\\\\RadioX\\\\ProjetTomo_A&L\\\\test_reconstruc_radon\\\\test%i.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035cb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permet de faire la transformée inverse de Radon sur toutes les images \n",
    "for k in range(180):\n",
    "    img1 = proj[k,:,:]  \n",
    "    reconstructed = iradon(gaussian,np.linspace(0, 180, img1.shape[1], endpoint=False))# Inverse de la transformée de Radon \n",
    "    reconstructed1 = iradon(img1,np.linspace(0, 180, img1.shape[1], endpoint=False), filter_name='hann') # Inverse de la transformée de Radon avec filtre de Hanning\n",
    "    reconstructed2 = iradon(gaussian,np.linspace(0, 180, img1.shape[1], endpoint=False), filter_name='hamming')# Inverse de la transformée de Radon avec filtre de Hamming\n",
    "\n",
    "#Permet d'enregistrer la reconstruction\n",
    "    cv2.imwrite('Chemin du dossier créé pour y mettre les images traitées/+nom de l'image%i.tif'%k,reconstructed)\n",
    "    \n",
    "#Permet d'afficher les images de reconstruction avec les differents filtres\n",
    "plt.subplot(121),plt.imshow(reconstructed,cmap=\"gray\"),plt.title('filtre hanning')\n",
    "plt.show()\n",
    "\n",
    "yxratio=reconstructed.shape[2]/reconstructed.shape[1]\n",
    "anim2 = create_animation(reconstructed, 4,4/yxratio)\n",
    "display(HTML(anim2.to_jshtml()))\n",
    "                \n",
    "plt.subplot(122),plt.imshow(reconstructed1,cmap=\"gray\"),plt.title('filtre gaussian')\n",
    "plt.show()\n",
    "                \n",
    "yxratio=reconstructed1.shape[2]/reconstructed1.shape[1]\n",
    "anim2 = create_animation(reconstructed1, 4,4/yxratio)\n",
    "display(HTML(anim2.to_jshtml()))\n",
    "\n",
    "plt.subplot(131),plt.imshow(reconstructed2,cmap=\"gray\"),plt.title('filtre hamming')\n",
    "plt.show()\n",
    "                \n",
    "yxratio=reconstructed2.shape[2]/reconstructed2.shape[1]\n",
    "anim2 = create_animation(reconstructed2, 4,4/yxratio)\n",
    "display(HTML(anim2.to_jshtml()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516a337",
   "metadata": {},
   "source": [
    "## Étape 7 : Sauvegarde de la reconstruction\n",
    "\n",
    "Pour les reconstructions précédentes qui ne nécessitent pas de boucles comme celle du dernier algorithme, vous allez exécuter le code suivant pour enregistrer les images. Choisissez le nom de vos images comme par exemple 'imagerec'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpim #Definir la bibliothèque\n",
    "\n",
    "IMAGE=\"imagerec%d.tiff\" #Nom des images reconstruites\n",
    "for i in range (0,694):\n",
    "    fichier=IMAGE %i # permet de donner le nom de l'image avec le numéro de l'image associée\n",
    "    mpim.imsave(fichier,rec[i,100:350,100:350]) #Permet de sauvegarder toute la reconstruction\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc520b11",
   "metadata": {},
   "source": [
    "## Étape 8 : Sélection des images utiles\n",
    "\n",
    "Maintenant, si vous regardez attentivement l'animation des reconstructions vous verrez que sur certaines images, aucune reconstruction est visible.\n",
    "\n",
    "Afin d'afficher une animation plus optimale il faut sélectionner les images utiles. Pour cela, vous allez seuiller les images afin d'obtenir des images ne comportant que des pixels noirs et blancs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation\n",
    "i=0\n",
    "dossier = 'Chemin du dossier contenant les images' \n",
    "num_image = [] #on definit des listes qui serviront à tracer les courbes\n",
    "blanc = []\n",
    "noir = []\n",
    "\n",
    "\n",
    "for i in range(0,500):\n",
    "    num_image.append(i)#ajouter à la liste num_image\n",
    "    img = cv2.imread('Chemin du dossier/+ nom image%i.tiff'%i, cv2.IMREAD_GRAYSCALE)\n",
    "    ret, thresh1 = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY) #permet de définir le seuil\n",
    "    n_white_pix = np.sum(thresh1 == 255)  #compter les pixels blancs dans l'image seuillée  \n",
    "    blanc.append(n_white_pix)\n",
    "    #print('Number of white pixels:', n_white_pix)\n",
    "    n_black_pix = np.sum(thresh1 == 0) #compter les pixels noirs dans l'image seuillée\n",
    "    noir.append(n_black_pix)\n",
    "    #print('Number of black pixels:', n_black_pix)\n",
    "\n",
    "#Affiche les graphiques pour trouver le numéro de l'image à partir de laquelle les reconstructions ne sont plus visibles.\n",
    "plt.subplot(121),plt.plot(num_image,blanc,\"r\")\n",
    "plt.subplot(122),plt.plot(num_image,noir,\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbea88d",
   "metadata": {},
   "source": [
    "## Étape intermédiaire entre les étapes 2 et 3 : Segmentation par binarisation\n",
    "\n",
    "Un autre point qui peut être utile lorsque le bruit de fond d’une image est trop important est de pouvoir segmenter l’image. C’est à dire pouvoir retirer l’objet de l’image et la mettre sur un fond blanc afin d’annuler toute source de bruit inutile sur l’image.\n",
    "\n",
    "Une autre segmentation intéressante est celle par binarisation. Les étapes de cette segmentation sont :\n",
    "1. Ouvrir l’image initial avec Image.open(« nom ») \n",
    "2. Création d’une image vide avec Image.new (‘RBV’, (dimx,dimy), (255,255,255)\n",
    "3. Parcours de l’image initiale et test de chaque pixel pour savoir si la norme des 8 voisins du pixel est supérieure à une valeur seuil choisie. Si tel est le cas alors le pixel est reformé sur l’image vide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies \n",
    "from PIL import Image\n",
    "from math import *\n",
    "\n",
    "#Ouverture de l'image en noir et blanc initiale\n",
    "image1 = Image.open(\"nom de l'image.tiff\") \n",
    "\n",
    "#Affiche l'image d'origine\n",
    "plt.imshow(image1)\n",
    "plt.show()\n",
    "\n",
    "# Récupération des dimensions de l'image\n",
    "dimx=image1.size[0] \n",
    "dimy=image1.size[1]\n",
    "\n",
    "# Création d'une image vide.\n",
    "image2 = Image.new ('RGB' , (dimx,dimy),(255,255,255)) \n",
    "\n",
    "#Binarisation\n",
    "for  y in range(1,dimy-1) :\n",
    "    for x in range ( 1,dimx-2):\n",
    "        rvbCentre = image1.getpixel((x,y)) # le pixel central \n",
    "        rvbVoisin1= image1.getpixel((x+1,y-1)) # Les 8 vois\n",
    "        rvbVoisin2= image1.getpixel((x-1,y+1))\n",
    "        rvbVoisin3= image1.getpixel((x-1,y-1))\n",
    "        rvbVoisin4= image1.getpixel((x+1,y+1))\n",
    "        rvbVoisin5= image1.getpixel((x,y-1))\n",
    "        rvbVoisin6= image1.getpixel((x,y+1))\n",
    "        rvbVoisin7= image1.getpixel((x-1,y))\n",
    "        rvbVoisin8= image1.getpixel((x+1,y))\n",
    "        norme=sqrt((rvbVoisin1[1]-rvbVoisin2[2])**2+(rvbVoisin3[1]-rvbVoisin4[1])**2+(rvbVoisin5[1]-rvbVoisin6[1])**2+(rvbVoisin7[1]-rvbVoisin8[1])**2)\n",
    "        if norme > 10 :\n",
    "            image2.putpixel((x,y),(0,0,0))\n",
    "\n",
    "#On sauvegarde la nouvelle image\n",
    "image2.save(\"contour.jpg\") \n",
    "plt.imshow(image2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c44b8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Plusieurs paramètres sont à prendre en compte si vous souhaitez une reconstruction adéquat. De plus, vous remarquerez, que les différents algorithmes ne sont pas tous adaptés pour certains types d'objets. C'est donc à vous de choisir l'algorithme qui permettra d'obtenir la reconstruction que vous souhaitez."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
